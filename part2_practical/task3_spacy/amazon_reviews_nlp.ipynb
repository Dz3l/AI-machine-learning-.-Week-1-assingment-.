{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: NLP with spaCy - Amazon Product Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal:**\n",
    "1. Perform named entity recognition (NER) to extract product names and brands.\n",
    "2. Analyze sentiment (positive/negative) using a rule-based approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Load spaCy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "# Load a small English spaCy model\n",
    "# You might need to download it first: python -m spacy download en_core_web_sm\n",
    "try:\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "except OSError:\n",
    "    print('Downloading language model for the spaCy POS tagger\\n(This is a one-time download)')\n",
    "    from spacy.cli import download\n",
    "    download('en_core_web_sm')\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# For rule-based sentiment analysis, we can use NLTK's VADER for simplicity\n",
    "# or build custom rules with spaCy's Matcher.\n",
    "try:\n",
    "    from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "except ImportError:\n",
    "    print(\"NLTK VADER not found. Installing nltk...\")\n",
    "    import subprocess\n",
    "    subprocess.check_call(['pip', 'install', 'nltk'])\n",
    "    import nltk\n",
    "    nltk.download('vader_lexicon')\n",
    "    from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk_downloaded = False\n",
    "try:\n",
    "    nltk.data.find('sentiment/vader_lexicon.zip')\n",
    "except nltk.downloader.DownloadError:\n",
    "    print(\"NLTK VADER lexicon not found. Downloading...\")\n",
    "    nltk.download('vader_lexicon')\n",
    "    nltk_downloaded = True\n",
    "\n",
    "if nltk_downloaded:\n",
    "    # Re-initialize after download if it was just downloaded in this session\n",
    "    from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sample Text Data (User Reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a small, sample dataset of Amazon product reviews.\n",
    "# In a real scenario, you'd load this from a CSV or database.\n",
    "reviews_data = [\n",
    "    {\"id\": 1, \"text\": \"The new iPhone 15 Pro is amazing! Camera quality is superb. Apple really outdid themselves.\"}, \n",
    "    {\"id\": 2, \"text\": \"I bought a Samsung Galaxy S23 and it's been a disappointment. The battery life is terrible.\"}, \n",
    "    {\"id\": 3, \"text\": \"Love my Sony WH-1000XM5 headphones. Best noise cancellation I've ever experienced from Sony.\"}, \n",
    "    {\"id\": 4, \"text\": \"This generic Bluetooth speaker is surprisingly good for its price. Not a Bose, but decent.\"}, \n",
    "    {\"id\": 5, \"text\": \"The Dell XPS 13 is a fantastic laptop, but it gets too hot sometimes. Still, Dell makes great machines.\"},\n",
    "    {\"id\": 6, \"text\": \"My Kindle Paperwhite is my favorite gadget. Amazon makes reading so easy.\"},\n",
    "    {\"id\": 7, \"text\": \"The Google Pixel 8 camera is incredible, but the phone feels a bit laggy compared to my old OnePlus.\"}\n",
    "]\n",
    "reviews_df = pd.DataFrame(reviews_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Named Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spaCy's default NER model can identify entities like `ORG` (organizations, often brands) and `PRODUCT`. We can also add custom patterns for more specific product types if needed, but for this task, we'll rely on the default model's capabilities and some keyword heuristics for products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(text):\n",
    "    doc = nlp(text)\n",
    "    entities = {'products': [], 'brands': []}\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == 'ORG':\n",
    "            # Simple check to avoid adding common words like 'Amazon' if it's not a brand in context\n",
    "            # This is a heuristic and can be improved.\n",
    "            if ent.text.lower() not in ['amazon'] or 'amazon makes' in text.lower(): \n
    "                entities['brands'].append(ent.text)\n",
    "        elif ent.label_ == 'PRODUCT':\n",
    "            entities['products'].append(ent.text)\n",
    "        # Heuristic: Look for Noun Chunks that might be products if not caught by PRODUCT\n",
    "        # This is very basic and would need refinement for real-world use.\n",
    "        # Often products are proper nouns or noun phrases near brand names.\n",
    "        # Example: "iPhone 15 Pro", "Galaxy S23", "WH-1000XM5 headphones"\n",
    "        # We can also look for patterns like [BRAND] [MODEL_NAME/NUMBER]\n",
    "        \n",
    "    # A simple heuristic for products: Nouns/Proper Nouns preceded by a brand or followed by a common product word\n",
    "    # This is more complex to implement robustly with just spaCy's basic NER without training.\n",
    "    # For now, we'll primarily rely on ORG for brands and PRODUCT for products, and list some common ones.\n",
    "    \n",
    "    # Add known product names if they appear and aren't caught as PRODUCT\n",
    "    # This is a placeholder for more advanced pattern matching or a product gazetteer\n",
    "    known_products_patterns = [\n",
    "        \"iPhone 15 Pro\", \"Galaxy S23\", \"WH-1000XM5 headphones\", \"XPS 13\", \n",
    "        \"Kindle Paperwhite\", \"Pixel 8\", \"Bluetooth speaker\"\n",
    "    ]\n",
    "    for pattern in known_products_patterns:\n",
    "        if pattern.lower() in text.lower() and pattern not in entities['products']:\n",
    "            entities['products'].append(pattern)\n",
    "            \n",
    "    # Deduplicate (in case heuristics overlap or model catches parts)\n",
    "    entities['products'] = list(set(entities['products']))\n",
    "    entities['brands'] = list(set(entities['brands']))\n",
    "    \n",
    "    return entities\n",
    "\n",
    "reviews_df['entities'] = reviews_df['text'].apply(extract_entities)\n",
    "\n",
    "print(\"Extracted Entities:\")\n",
    "for index, row in reviews_df.iterrows():\n",
    "    print(f\"Review {row['id']}: Brands: {row['entities']['brands']}, Products: {row['entities']['products']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note on NER for Products/Brands:**\n",
    "Extracting product names and brands accurately can be challenging with general-purpose NER models. \n",
    "- `ORG` often captures brands (e.g., Apple, Samsung, Sony, Dell, Google, Amazon, OnePlus).\n",
    "- `PRODUCT` might capture some well-known products, but coverage can be spotty for specific models or less common items.\n",
    "For robust extraction, one would typically:\n",
    "1.  **Use rule-based matching with spaCy's `Matcher` or `PhraseMatcher`**: Define patterns for product names (e.g., `BRAND_NAME + MODEL_NUMBER`, `PRODUCT_CATEGORY_KEYWORD`).\n",
    "2.  **Train a custom NER model**: If you have a large dataset of reviews with annotated product names and brands, you can fine-tune a spaCy model or train one from scratch for better domain-specific accuracy.\n",
    "3.  **Gazetteers**: Use lists of known brands and product keywords.\n",
    "\n",
    "The solution above uses the default `en_core_web_sm` entities and adds a simple heuristic for known product strings. This is a simplification for the assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sentiment Analysis (Rule-Based)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use NLTK's VADER (Valence Aware Dictionary and sEntiment Reasoner) for a rule-based sentiment analysis. VADER is specifically attuned to sentiments expressed in social media and works well on texts from similar domains like product reviews. It provides a compound score ranging from -1 (most negative) to +1 (most positive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment_vader(text):\n",
    "    sentiment_scores = sid.polarity_scores(text)\n",
    "    compound_score = sentiment_scores['compound']\n",
    "    if compound_score >= 0.05:\n",
    "        return 'positive'\n",
    "    elif compound_score <= -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "reviews_df['sentiment_vader'] = reviews_df['text'].apply(analyze_sentiment_vader)\n",
    "\n",
    "print(\"\\nSentiment Analysis Results (VADER):\")\n",
    "for index, row in reviews_df.iterrows():\n",
    "    print(f\"Review {row['id']}: '{row['text'][:50]}...' - Sentiment: {row['sentiment_vader']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative: spaCy Rule-Based Sentiment (Conceptual)\n",
    "If we were to build a more custom rule-based system with spaCy, we might:\n",
    "1.  Define lists of positive and negative keywords.\n",
    "2.  Use spaCy's `Matcher` to find these keywords in the text.\n",
    "3.  Consider negations (e.g., \"not good\") and intensifiers (e.g., \"very good\").\n",
    "4.  Develop a scoring logic based on the presence and context of these keywords.\n",
    "\n",
    "**Example (very basic concept for spaCy custom rules):**\n",
    "```python\n",
    "# from spacy.matcher import Matcher\n",
    "# matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# # Define patterns for positive and negative words\n",
    "# positive_patterns = [[{'LOWER': 'amazing'}], [{'LOWER': 'superb'}], [{'LOWER': 'love'}]]\n",
    "# negative_patterns = [[{'LOWER': 'disappointment'}], [{'LOWER': 'terrible'}], [{'LOWER': 'too', 'OP': '?'}, {'LOWER': 'hot'}]]\n",
    "\n",
    "# matcher.add(\"POSITIVE\", positive_patterns)\n",
    "# matcher.add(\"NEGATIVE\", negative_patterns)\n",
    "\n",
    "# def analyze_sentiment_spacy_custom(text):\n",
    "#     doc = nlp(text)\n",
    "#     matches = matcher(doc)\n",
    "#     pos_score = 0\n",
    "#     neg_score = 0\n",
    "#     for match_id, start, end in matches:\n",
    "#         rule_id = nlp.vocab.strings[match_id]\n",
    "#         if rule_id == 'POSITIVE':\n",
    "#             pos_score += 1\n",
    "#         elif rule_id == 'NEGATIVE':\n",
    "#             neg_score += 1\n",
    "            \n",
    "#     if pos_score > neg_score:\n",
    "#         return 'positive'\n",
    "#     elif neg_score > pos_score:\n",
    "#         return 'negative'\n",
    "#     else:\n",
    "#         return 'neutral'\n",
    "```\n",
    "This custom spaCy approach is more involved than using VADER and would require careful crafting of rules and patterns for good performance. VADER is a good off-the-shelf choice for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Combined Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Combined Results ---\")\n",
    "for i in range(len(reviews_df)):\n",
    "    review = reviews_df.iloc[i]\n",
    "    print(f\"\\nReview ID: {review['id']}\")\n",
    "    print(f\"Text: {review['text']}\")\n",
    "    print(f\"  Extracted Brands: {review['entities']['brands']}\")\n",
    "    print(f\"  Extracted Products: {review['entities']['products']}\")\n",
    "    print(f\"  Sentiment (VADER): {review['sentiment_vader']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
