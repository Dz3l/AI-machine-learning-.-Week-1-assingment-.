{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Deep Learning with TensorFlow/PyTorch - MNIST Handwritten Digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal:**\n",
    "1. Build a CNN model to classify handwritten digits.\n",
    "2. Achieve >95% test accuracy.\n",
    "3. Visualize the modelâ€™s predictions on 5 sample images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries (using TensorFlow for this example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Preprocess MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Preprocess images\n",
    "# Reshape data to fit the model (add channel dimension)\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Preprocess labels (one-hot encode)\n",
    "y_train_categorical = to_categorical(y_train, num_classes=10)\n",
    "y_test_categorical = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"y_train_categorical shape: {y_train_categorical.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}\")\n",
    "print(f\"y_test_categorical shape: {y_test_categorical.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    # Convolutional Layer 1\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # Convolutional Layer 2\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # Flattening Layer\n",
    "    Flatten(),\n",
    "    \n",
    "    # Fully Connected (Dense) Layer\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5), # Dropout for regularization\n",
    "    \n",
    "    # Output Layer\n",
    "    Dense(10, activation='softmax') # 10 classes for digits 0-9\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture Explanation:\n",
    "- **Conv2D (Convolutional Layer):** Applies filters to the input image to create feature maps. `32` and `64` are the number of filters. `kernel_size=(3,3)` is the size of the filter. `activation='relu'` introduces non-linearity.\n",
    "- **MaxPooling2D:** Downsamples the feature maps, reducing dimensionality and helping to make the model more robust to variations in the input.\n",
    "- **Flatten:** Converts the 2D feature maps into a 1D vector to be fed into the Dense layers.\n",
    "- **Dense (Fully Connected Layer):** A standard neural network layer where each neuron is connected to all neurons in the previous layer. `128` is the number of neurons.\n",
    "- **Dropout:** A regularization technique where randomly selected neurons are ignored during training. This helps prevent overfitting. `0.5` means 50% of neurons are dropped.\n",
    "- **Output Layer (Dense):** Has `10` neurons (one for each digit) and uses `softmax` activation to output probabilities for each class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 10 # Can be increased if needed to reach >95% accuracy\n",
    "\n",
    "history = model.fit(x_train, y_train_categorical, \n",
    "                    epochs=epochs, \n",
    "                    batch_size=batch_size, \n",
    "                    validation_split=0.1) # Use part of training data for validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate the Model on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test_categorical, verbose=0)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "if accuracy > 0.95:\n",
    "    print(\"\\nModel achieved >95% test accuracy!\")\n",
    "else:\n",
    "    print(\"\\nModel did not achieve >95% test accuracy. Consider training for more epochs or adjusting the architecture.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Predictions on Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for the test set\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "# Select 5 random sample images from the test set\n",
    "num_samples = 5\n",
    "sample_indices = np.random.choice(x_test.shape[0], num_samples, replace=False)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, index in enumerate(sample_indices):\n",
    "    plt.subplot(1, num_samples, i + 1)\n",
    "    plt.imshow(x_test[index].reshape(28, 28), cmap='gray')\n",
    "    predicted_label = np.argmax(predictions[index])\n",
    "    true_label = np.argmax(y_test_categorical[index]) # Original y_test[index] would also work\n",
    "    plt.title(f\"Pred: {predicted_label}\\nTrue: {true_label}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop Explanation:\n",
    "- **`model.fit()`:** This function trains the model.\n",
    "- **`x_train, y_train_categorical`:** The training data and corresponding one-hot encoded labels.\n",
    "- **`epochs`:** The number of times the model will iterate over the entire training dataset.\n",
    "- **`batch_size`:** The number of samples processed before the model's internal parameters are updated.\n",
    "- **`validation_split=0.1`:** Reserves 10% of the training data to be used as validation data. The model's performance on this validation set is monitored during training, which can help detect overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
